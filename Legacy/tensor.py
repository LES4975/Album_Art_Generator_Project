import tensorflow as tf
import numpy as np
from pathlib import Path
import json


class TensorFlowModelAnalyzer:
    def __init__(self):
        """TensorFlow .pb ëª¨ë¸ íŒŒì¼ ë¶„ì„ê¸°"""
        self.analyzed_models = {}

    def load_pb_model(self, model_path):
        """
        .pb íŒŒì¼ì„ ë¡œë“œí•˜ê³  GraphDefë¥¼ ë°˜í™˜
        """
        try:
            with tf.io.gfile.GFile(str(model_path), "rb") as f:
                graph_def = tf.compat.v1.GraphDef()
                graph_def.ParseFromString(f.read())

            # ê·¸ë˜í”„ ìƒì„±
            graph = tf.Graph()
            with graph.as_default():
                tf.import_graph_def(graph_def, name="")

            return graph, graph_def

        except Exception as e:
            print(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨ ({model_path}): {e}")
            return None, None

    def analyze_model_structure(self, model_path, model_name):
        """
        ëª¨ë¸ì˜ ì „ì²´ êµ¬ì¡°ë¥¼ ë¶„ì„
        """
        print(f"\n{'=' * 60}")
        print(f"ğŸ” {model_name} ë¶„ì„ ì‹œì‘")
        print(f"ğŸ“ íŒŒì¼: {model_path}")
        print(f"{'=' * 60}")

        graph, graph_def = self.load_pb_model(model_path)
        if graph is None:
            return None

        analysis_result = {
            "model_name": model_name,
            "model_path": str(model_path),
            "total_operations": len(graph_def.node),
            "operations": [],
            "placeholders": [],
            "outputs": [],
            "input_tensors": [],
            "output_tensors": []
        }

        print(f"ğŸ“Š ì´ ì—°ì‚° ìˆ˜: {len(graph_def.node)}")
        print(f"\nğŸ“‹ ëª¨ë“  ì—°ì‚° ëª©ë¡:")

        # ëª¨ë“  ì—°ì‚° ë¶„ì„
        for i, node in enumerate(graph_def.node, 1):
            op_info = {
                "index": i,
                "name": node.name,
                "type": node.op,
                "inputs": list(node.input),
                "outputs": []
            }

            # ì¶œë ¥ í…ì„œ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            try:
                with graph.as_default():
                    # ê·¸ë˜í”„ì—ì„œ í•´ë‹¹ ì—°ì‚°ì˜ ì¶œë ¥ë“¤ ì°¾ê¸°
                    operation = graph.get_operation_by_name(node.name)
                    for j, output in enumerate(operation.outputs):
                        output_info = {
                            "name": output.name,
                            "shape": output.shape.as_list() if output.shape.is_fully_defined() else [
                                None if dim.value is None else dim.value for dim in output.shape.dims],
                            "dtype": str(output.dtype)
                        }
                        op_info["outputs"].append(output_info)
            except:
                # ì—°ì‚°ì„ ì°¾ì„ ìˆ˜ ì—†ëŠ” ê²½ìš° (ì¼ë¶€ ë‚´ë¶€ ì—°ì‚°ë“¤)
                pass

            analysis_result["operations"].append(op_info)

            # Placeholder íƒ€ì… ì°¾ê¸°
            if node.op == "Placeholder":
                placeholder_info = {
                    "name": node.name,
                    "outputs": op_info["outputs"]
                }
                analysis_result["placeholders"].append(placeholder_info)
                analysis_result["input_tensors"].extend([out["name"] for out in op_info["outputs"]])

            # ì¶œë ¥ í˜•íƒœì˜ ì—°ì‚°ë“¤ ì°¾ê¸° (ì¼ë°˜ì ìœ¼ë¡œ ë§ˆì§€ë§‰ ì—°ì‚°ë“¤)
            output_types = ["Sigmoid", "Softmax", "Identity", "PartitionedCall", "StatefulPartitionedCall"]
            if node.op in output_types:
                output_info = {
                    "name": node.name,
                    "type": node.op,
                    "outputs": op_info["outputs"]
                }
                analysis_result["outputs"].append(output_info)
                analysis_result["output_tensors"].extend([out["name"] for out in op_info["outputs"]])

            # ì—°ì‚° ì •ë³´ ì¶œë ¥
            print(f"   {i:3d}. {node.name} (íƒ€ì…: {node.op})")
            for output in op_info["outputs"]:
                print(
                    f"       ì¶œë ¥ {op_info['outputs'].index(output)}: {output['name']} - ëª¨ì–‘: {output['shape']}, íƒ€ì…: {output['dtype']}")

        # Placeholder ì •ë³´ ì¶œë ¥
        print(f"\nğŸ¯ ì…ë ¥ ë…¸ë“œë“¤ (Placeholder):")
        if analysis_result["placeholders"]:
            for i, placeholder in enumerate(analysis_result["placeholders"], 1):
                print(f"   {i}. {placeholder['name']}")
                for output in placeholder["outputs"]:
                    print(f"      â€¢ {output['name']} - ëª¨ì–‘: {output['shape']}, íƒ€ì…: {output['dtype']}")
        else:
            print("   ì…ë ¥ ë…¸ë“œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        # ì¶œë ¥ ë…¸ë“œ ì •ë³´
        print(f"\nğŸ¯ ì¶œë ¥ ë…¸ë“œë“¤:")
        if analysis_result["outputs"]:
            for i, output in enumerate(analysis_result["outputs"], 1):
                print(f"   {i}. {output['name']} (íƒ€ì…: {output['type']})")
                for out_tensor in output["outputs"]:
                    print(f"      â€¢ {out_tensor['name']} - ëª¨ì–‘: {out_tensor['shape']}, íƒ€ì…: {out_tensor['dtype']}")
        else:
            print("   ì¶œë ¥ ë…¸ë“œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        # ì¶”ì²œ ì…ì¶œë ¥ í…ì„œ
        print(f"\nğŸ’¡ ì¶”ì²œ ì…ì¶œë ¥ í…ì„œ:")
        if analysis_result["input_tensors"]:
            print(f"   ğŸ“¥ ì…ë ¥ í…ì„œ: {analysis_result['input_tensors'][0]}")
        if analysis_result["output_tensors"]:
            # ê°€ì¥ ê°€ëŠ¥ì„± ë†’ì€ ì¶œë ¥ í…ì„œ ì„ íƒ
            recommended_output = None
            for tensor_name in analysis_result["output_tensors"]:
                if "Sigmoid" in tensor_name or "Softmax" in tensor_name:
                    recommended_output = tensor_name
                    break
            if not recommended_output and analysis_result["output_tensors"]:
                recommended_output = analysis_result["output_tensors"][-1]

            print(f"   ğŸ“¤ ì¶œë ¥ í…ì„œ: {recommended_output}")

        # ê²°ê³¼ ì €ì¥
        self.analyzed_models[model_name] = analysis_result
        return analysis_result

    def find_serving_signatures(self, model_path, model_name):
        """
        SavedModel í˜•íƒœì˜ ì„œë¹™ ì‹œê·¸ë‹ˆì²˜ë¥¼ ì°¾ê¸° (ì¼ë¶€ .pb íŒŒì¼ì—ì„œ ê°€ëŠ¥)
        """
        try:
            graph, _ = self.load_pb_model(model_path)
            if graph is None:
                return

            print(f"\nğŸ” {model_name} ì„œë¹™ ì‹œê·¸ë‹ˆì²˜ ë¶„ì„:")

            # serving_defaultë¡œ ì‹œì‘í•˜ëŠ” ë…¸ë“œë“¤ ì°¾ê¸°
            serving_nodes = []
            with graph.as_default():
                for op in graph.get_operations():
                    if "serving_default" in op.name:
                        serving_nodes.append(op)

            if serving_nodes:
                print("   ğŸ“¡ ì„œë¹™ ê´€ë ¨ ë…¸ë“œë“¤:")
                for node in serving_nodes:
                    print(f"      â€¢ {node.name} (íƒ€ì…: {node.type})")
                    for output in node.outputs:
                        print(f"        ì¶œë ¥: {output.name} - ëª¨ì–‘: {output.shape}")
            else:
                print("   ì„œë¹™ ì‹œê·¸ë‹ˆì²˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        except Exception as e:
            print(f"   ì„œë¹™ ì‹œê·¸ë‹ˆì²˜ ë¶„ì„ ì‹¤íŒ¨: {e}")

    def save_analysis_to_file(self, model_name, output_file=None):
        """
        ë¶„ì„ ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥
        """
        if model_name not in self.analyzed_models:
            print(f"âŒ {model_name} ëª¨ë¸ ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        if output_file is None:
            output_file = f"{model_name}_analysis.txt"

        result = self.analyzed_models[model_name]

        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(f"=== {model_name} ëª¨ë¸ ë¶„ì„ ê²°ê³¼ ===\n\n")
            f.write(f"ì´ ì—°ì‚° ìˆ˜: {result['total_operations']}\n\n")

            f.write("=== ëª¨ë“  ì—°ì‚° ëª©ë¡ ===\n")
            for op in result['operations']:
                f.write(f"   {op['index']}. {op['name']} (íƒ€ì…: {op['type']})\n")
                for output in op['outputs']:
                    f.write(
                        f"       ì¶œë ¥ {op['outputs'].index(output)}: {output['name']} - ëª¨ì–‘: {output['shape']}, íƒ€ì…: {output['dtype']}\n")
                f.write("\n")

        print(f"âœ… ë¶„ì„ ê²°ê³¼ê°€ {output_file}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

    def compare_models(self):
        """
        ë¶„ì„ëœ ëª¨ë¸ë“¤ì„ ë¹„êµ
        """
        if len(self.analyzed_models) < 2:
            print("ë¹„êµí•  ëª¨ë¸ì´ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            return

        print(f"\n{'=' * 60}")
        print("ğŸ”„ ëª¨ë¸ ë¹„êµ ë¶„ì„")
        print(f"{'=' * 60}")

        for name, result in self.analyzed_models.items():
            print(f"\nğŸ“‹ {name}:")
            print(f"   â€¢ ì´ ì—°ì‚° ìˆ˜: {result['total_operations']}")
            print(f"   â€¢ ì…ë ¥ í…ì„œ ìˆ˜: {len(result['input_tensors'])}")
            print(f"   â€¢ ì¶œë ¥ í…ì„œ ìˆ˜: {len(result['output_tensors'])}")

            if result['input_tensors']:
                print(f"   â€¢ ì£¼ìš” ì…ë ¥: {result['input_tensors'][0]}")
            if result['output_tensors']:
                print(f"   â€¢ ì£¼ìš” ì¶œë ¥: {result['output_tensors'][-1]}")


def main():
    """
    ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
    """
    analyzer = TensorFlowModelAnalyzer()

    # ë¶„ì„í•  ëª¨ë¸ë“¤ ì •ì˜
    models_to_analyze = [
        {
            "path": "models/discogs-effnet-bs64-1.pb",
            "name": "discogs-effnet-bs64-1"
        },
        {
            "path": "models/mtg_jamendo_moodtheme-discogs-effnet-1.pb",
            "name": "mtg_jamendo_moodtheme-discogs-effnet-1"
        },
        {
            "path": "models/genre_discogs400-discogs-effnet-1.pb",
            "name": "genre_discogs400-discogs-effnet-1"
        }
    ]

    print("ğŸ” TensorFlow .pb ëª¨ë¸ êµ¬ì¡° ë¶„ì„ê¸°")
    print("íŠ¹íˆ ì¥ë¥´ ëª¨ë¸ì˜ ì˜¬ë°”ë¥¸ ì…ë ¥ í…ì„œ ì´ë¦„ ì°¾ê¸°ì— ì¤‘ì ")
    print("=" * 70)

    # ê° ëª¨ë¸ ë¶„ì„
    for model_info in models_to_analyze:
        model_path = Path(model_info["path"])

        if model_path.exists():
            # ê¸°ë³¸ êµ¬ì¡° ë¶„ì„
            result = analyzer.analyze_model_structure(model_path, model_info["name"])

            # ì„œë¹™ ì‹œê·¸ë‹ˆì²˜ ë¶„ì„
            analyzer.find_serving_signatures(model_path, model_info["name"])

            # ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥
            analyzer.save_analysis_to_file(model_info["name"])

        else:
            print(f"âŒ ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_path}")

    # ëª¨ë¸ë“¤ ë¹„êµ
    analyzer.compare_models()

    print(f"\n{'=' * 70}")
    print("âœ… ëª¨ë“  ëª¨ë¸ ë¶„ì„ ì™„ë£Œ!")
    print("ê° ëª¨ë¸ì˜ ìƒì„¸ ë¶„ì„ ê²°ê³¼ëŠ” ê°œë³„ í…ìŠ¤íŠ¸ íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")


if __name__ == "__main__":
    main()