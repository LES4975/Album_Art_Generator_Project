# memory_optimized_generator.py
# T4 GPUìš© ì´ˆê²½ëŸ‰ ì•¨ë²” ì•„íŠ¸ ìƒì„±ê¸°

import torch
from diffusers import StableDiffusionPipeline, DPMSolverMultistepScheduler
import gc
import psutil
from pathlib import Path


class LightweightAlbumArtGenerator:
    """T4 GPU ë©”ëª¨ë¦¬ ìµœì í™” ì•¨ë²” ì•„íŠ¸ ìƒì„±ê¸°"""

    def __init__(self, model_id="runwayml/stable-diffusion-v1-5"):
        """
        ì´ˆê²½ëŸ‰ ìƒì„±ê¸° ì´ˆê¸°í™”

        Args:
            model_id: ê²½ëŸ‰ ëª¨ë¸ ID (SD 1.5 ì‚¬ìš©)
        """
        self.model_id = model_id
        self.pipeline = None
        self.device = "cuda" if torch.cuda.is_available() else "cpu"

        print(f"ğŸª¶ ì´ˆê²½ëŸ‰ ìƒì„±ê¸° ì´ˆê¸°í™” ì¤‘... (ë””ë°”ì´ìŠ¤: {self.device})")
        self._setup_pipeline()

    def _setup_pipeline(self):
        """ì´ˆê²½ëŸ‰ íŒŒì´í”„ë¼ì¸ ì„¤ì •"""
        try:
            # ë©”ëª¨ë¦¬ ìƒíƒœ ì²´í¬
            self._check_memory()

            # SD 1.5 ë¡œë“œ (SDXLë³´ë‹¤ í›¨ì”¬ ê°€ë²¼ì›€)
            print(f"ğŸ“¦ ê²½ëŸ‰ ëª¨ë¸ ë¡œë”©: {self.model_id}")

            self.pipeline = StableDiffusionPipeline.from_pretrained(
                self.model_id,
                torch_dtype=torch.float16 if self.device == "cuda" else torch.float32,
                safety_checker=None,
                requires_safety_checker=False,
                use_safetensors=True,
                low_cpu_mem_usage=True
            )

            # ë¹ ë¥¸ ìŠ¤ì¼€ì¤„ëŸ¬ë¡œ êµì²´
            self.pipeline.scheduler = DPMSolverMultistepScheduler.from_config(
                self.pipeline.scheduler.config
            )

            if self.device == "cuda":
                # ìµœëŒ€ ë©”ëª¨ë¦¬ ì ˆì•½ ì„¤ì •
                self.pipeline.enable_model_cpu_offload()  # ëª¨ë¸ë“¤ì„ CPUë¡œ ì˜¤í”„ë¡œë“œ
                self.pipeline.enable_attention_slicing()  # ì–´í…ì…˜ ìŠ¬ë¼ì´ì‹±
                self.pipeline.enable_vae_slicing()  # VAE ìŠ¬ë¼ì´ì‹±

                print("âœ… ì´ˆê²½ëŸ‰ GPU íŒŒì´í”„ë¼ì¸ ë¡œë“œ ì™„ë£Œ")
            else:
                print("âœ… ì´ˆê²½ëŸ‰ CPU íŒŒì´í”„ë¼ì¸ ë¡œë“œ ì™„ë£Œ")

            # ë©”ëª¨ë¦¬ ì •ë¦¬
            self._cleanup_memory()

        except Exception as e:
            print(f"âŒ ì´ˆê²½ëŸ‰ íŒŒì´í”„ë¼ì¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            self.pipeline = None

    def _check_memory(self):
        """ë©”ëª¨ë¦¬ ìƒíƒœ í™•ì¸"""
        # RAM í™•ì¸
        memory = psutil.virtual_memory()
        print(f"ğŸ“Š RAM ì‚¬ìš©ë¥ : {memory.percent:.1f}% ({memory.used / 1e9:.1f}GB/{memory.total / 1e9:.1f}GB)")

        # GPU ë©”ëª¨ë¦¬ í™•ì¸
        if torch.cuda.is_available():
            gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9
            allocated = torch.cuda.memory_allocated() / 1e9
            print(f"ğŸ“Š GPU ë©”ëª¨ë¦¬: {allocated:.1f}GB/{gpu_memory:.1f}GB ì‚¬ìš© ì¤‘")

    def _cleanup_memory(self):
        """ë©”ëª¨ë¦¬ ì •ë¦¬"""
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        gc.collect()
        print("ğŸ§¹ ë©”ëª¨ë¦¬ ì •ë¦¬ ì™„ë£Œ")

    def generate_image(self, prompt, negative_prompt="", num_steps=10,
                       guidance_scale=7.5, width=512, height=512, seed=-1):
        """
        ê²½ëŸ‰ ì´ë¯¸ì§€ ìƒì„±

        Args:
            num_steps: 10-20 ìŠ¤í… (ë¹ ë¥¸ ìƒì„±)
            width, height: 512x512 ê¶Œì¥ (ë©”ëª¨ë¦¬ ì ˆì•½)
        """
        if self.pipeline is None:
            return None, "âŒ íŒŒì´í”„ë¼ì¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"

        try:
            print(f"ğŸª¶ ê²½ëŸ‰ ì´ë¯¸ì§€ ìƒì„± ì‹œì‘... ({width}x{height})")
            print(f"ğŸ“ í”„ë¡¬í”„íŠ¸: {prompt}")

            # ë©”ëª¨ë¦¬ ì •ë¦¬
            self._cleanup_memory()

            # ì‹œë“œ ì„¤ì •
            if seed != -1:
                torch.manual_seed(seed)
                if torch.cuda.is_available():
                    torch.cuda.manual_seed(seed)

            # ì´ë¯¸ì§€ ìƒì„± (ê²½ëŸ‰ ì„¤ì •)
            result = self.pipeline(
                prompt=prompt,
                negative_prompt=negative_prompt if negative_prompt else None,
                num_inference_steps=num_steps,  # ì ì€ ìŠ¤í…ìœ¼ë¡œ ë¹ ë¥´ê²Œ
                guidance_scale=guidance_scale,
                width=width,
                height=height
            )

            # ìƒì„± í›„ ë©”ëª¨ë¦¬ ì •ë¦¬
            self._cleanup_memory()

            print("âœ… ê²½ëŸ‰ ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ!")
            return result.images[0], None

        except Exception as e:
            error_msg = f"âŒ ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨: {str(e)}"
            print(error_msg)
            self._cleanup_memory()
            return None, error_msg

    def create_album_art_prompt(self, music_analysis, music_title="Unknown"):
        """ìŒì•… ë¶„ì„ì„ ë°”íƒ•ìœ¼ë¡œ SD 1.5ìš© í”„ë¡¬í”„íŠ¸ ìƒì„±"""

        if "error" in music_analysis:
            return (f"album cover for {music_title}, artistic design, professional",
                    "text, words, blurry, low quality, ugly")

        # ê¸°ë³¸ ì•¨ë²” ì»¤ë²„ ìŠ¤íƒ€ì¼
        prompt_parts = [
            f"album cover for '{music_title}'",
            "professional music artwork",
            "artistic design",
            "high quality illustration"
        ]

        # ì¥ë¥´ ì •ë³´ ì¶”ê°€
        genres = music_analysis.get('genres', {}).get('top_genres', [])
        if genres:
            genre = genres[0]['genre']
            prompt_parts.append(f"{genre} music style")

        # ë¶„ìœ„ê¸° ì •ë³´ ì¶”ê°€
        moods = music_analysis.get('moods', {})
        prominent_moods = moods.get('prominent_moods', [])
        if prominent_moods:
            mood_text = ", ".join(prominent_moods[:2])
            prompt_parts.append(f"{mood_text} mood")
        elif moods.get('top_all'):
            top_mood = moods['top_all'][0][0]
            prompt_parts.append(f"{top_mood} atmosphere")

        # SD 1.5ì— ì í•©í•œ ìŠ¤íƒ€ì¼ í‚¤ì›Œë“œ
        prompt_parts.extend([
            "detailed artwork",
            "vibrant colors",
            "digital art",
            "trending on artstation"
        ])

        final_prompt = ", ".join(prompt_parts)
        negative_prompt = "text, words, letters, watermark, signature, blurry, low quality, ugly, deformed"

        return final_prompt, negative_prompt


# Gradio ì•±ìš© ê²½ëŸ‰ ë˜í¼
class LightweightGradioApp:
    """ê²½ëŸ‰ Gradio ì•±"""

    def __init__(self, music_classifier=None):
        self.generator = LightweightAlbumArtGenerator()
        self.music_classifier = music_classifier

    def process_music_to_art(self, audio_file, num_steps=10, width=512, height=512):
        """ê²½ëŸ‰ ìŒì•…â†’ì•„íŠ¸ íŒŒì´í”„ë¼ì¸"""

        if audio_file is None:
            return None, "âŒ ìŒì•… íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”", "", ""

        music_title = Path(audio_file).stem

        # 1. ìŒì•… ë¶„ì„ (ë¶„ë¥˜ê¸°ê°€ ìˆìœ¼ë©´)
        if self.music_classifier:
            print("ğŸ”„ ìŒì•… ë¶„ì„ ì¤‘...")
            with open(audio_file, 'rb') as f:
                audio_data = f.read()

            # ì„ì‹œ íŒŒì¼ë¡œ ë¶„ì„
            import tempfile
            with tempfile.NamedTemporaryFile(delete=False, suffix=".mp3") as tmp_file:
                tmp_file.write(audio_data)
                tmp_path = tmp_file.name

            try:
                music_result = self.music_classifier.classify_music(tmp_path)
                analysis_text = self._format_analysis(music_result)
                os.unlink(tmp_path)
            except:
                music_result = {"error": "ë¶„ì„ ì‹¤íŒ¨"}
                analysis_text = "ìŒì•… ë¶„ì„ ì‹¤íŒ¨"
        else:
            music_result = {"error": "ë¶„ë¥˜ê¸° ì—†ìŒ"}
            analysis_text = "ìŒì•… ë¶„ë¥˜ê¸°ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"

        # 2. í”„ë¡¬í”„íŠ¸ ìƒì„±
        prompt, negative_prompt = self.generator.create_album_art_prompt(music_result, music_title)

        # 3. ì´ë¯¸ì§€ ìƒì„±
        print("ğŸ”„ ê²½ëŸ‰ ì´ë¯¸ì§€ ìƒì„± ì¤‘...")
        image, error = self.generator.generate_image(
            prompt, negative_prompt, num_steps, width=width, height=height
        )

        if error:
            return None, f"âŒ {error}", analysis_text, prompt

        return image, "âœ… ê²½ëŸ‰ ì•¨ë²” ì•„íŠ¸ ìƒì„± ì™„ë£Œ!", analysis_text, prompt

    def _format_analysis(self, result):
        """ë¶„ì„ ê²°ê³¼ í¬ë§·íŒ…"""
        if "error" in result:
            return f"ì˜¤ë¥˜: {result['error']}"

        text_parts = []
        duration = result.get('audio_duration', 0)
        text_parts.append(f"â±ï¸ ê¸¸ì´: {duration:.1f}ì´ˆ")

        genres = result.get('genres', {}).get('top_genres', [])
        if genres:
            text_parts.append(f"\nğŸ¼ ìƒìœ„ ì¥ë¥´: {genres[0]['genre']}")

        moods = result.get('moods', {}).get('top_all', [])
        if moods:
            text_parts.append(f"ğŸ­ ì£¼ìš” ë¶„ìœ„ê¸°: {moods[0][0]}")

        return "\n".join(text_parts)


# ì‚¬ìš© ì˜ˆì‹œ
def create_lightweight_app(music_classifier=None):
    """ê²½ëŸ‰ ì•± ìƒì„±"""
    import gradio as gr

    app = LightweightGradioApp(music_classifier)

    with gr.Blocks(title="ğŸª¶ ê²½ëŸ‰ ì•¨ë²” ì•„íŠ¸ ìƒì„±ê¸°") as demo:
        gr.Markdown("""
        # ğŸª¶ ê²½ëŸ‰ ì•¨ë²” ì•„íŠ¸ ìƒì„±ê¸°
        ## T4 GPU ë©”ëª¨ë¦¬ ìµœì í™” ë²„ì „

        - **ëª¨ë¸**: Stable Diffusion 1.5 (ê²½ëŸ‰)
        - **í•´ìƒë„**: 512x512 (ë©”ëª¨ë¦¬ ì ˆì•½)
        - **ì†ë„**: 10-20 ìŠ¤í… (ë¹ ë¥¸ ìƒì„±)
        """)

        with gr.Row():
            with gr.Column():
                audio_input = gr.File(label="ğŸµ ìŒì•… íŒŒì¼", file_types=[".mp3", ".wav"])

                with gr.Row():
                    width_input = gr.Slider(label="ë„ˆë¹„", minimum=256, maximum=768, step=64, value=512)
                    height_input = gr.Slider(label="ë†’ì´", minimum=256, maximum=768, step=64, value=512)

                steps_input = gr.Slider(label="ìƒì„± ìŠ¤í…", minimum=5, maximum=25, step=5, value=10)
                generate_btn = gr.Button("ğŸª¶ ê²½ëŸ‰ ìƒì„±", variant="primary")

            with gr.Column():
                status_output = gr.Textbox(label="ìƒíƒœ", interactive=False)
                image_output = gr.Image(label="ìƒì„± ì´ë¯¸ì§€", height=400)

        with gr.Accordion("ë¶„ì„ ê²°ê³¼", open=False):
            analysis_output = gr.Textbox(label="ìŒì•… ë¶„ì„", lines=5)
            prompt_output = gr.Textbox(label="ìƒì„± í”„ë¡¬í”„íŠ¸", lines=3)

        generate_btn.click(
            fn=app.process_music_to_art,
            inputs=[audio_input, steps_input, width_input, height_input],
            outputs=[image_output, status_output, analysis_output, prompt_output]
        )

    return demo


# ì§ì ‘ ì‹¤í–‰
if __name__ == "__main__":
    demo = create_lightweight_app()
    demo.launch(share=True)